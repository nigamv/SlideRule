{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_39</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.144667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0   1               1             D3              26        0.487179   \n",
       "1   3               1             A2              26        0.076923   \n",
       "2   4               1             D3              26        0.144667   \n",
       "3   9               1             A1              26        0.151709   \n",
       "4  12               1             A1              26        0.076923   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n",
       "0               2               3               1  0.611940  0.781818   \n",
       "1               2               3               1  0.626866  0.727273   \n",
       "2               2               3               1  0.582090  0.709091   \n",
       "3               2               1               1  0.522388  0.654545   \n",
       "4               2               3               1  0.298507  0.672727   \n",
       "\n",
       "          ...          Medical_Keyword_39  Medical_Keyword_40  \\\n",
       "0         ...                           0                   0   \n",
       "1         ...                           0                   0   \n",
       "2         ...                           0                   0   \n",
       "3         ...                           0                   0   \n",
       "4         ...                           0                   0   \n",
       "\n",
       "   Medical_Keyword_41  Medical_Keyword_42  Medical_Keyword_43  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_44  Medical_Keyword_45  Medical_Keyword_46  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_47  Medical_Keyword_48  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   1                   1  \n",
       "4                   0                   0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv',delimiter=',', encoding=\"utf-8-sig\")\n",
    "\n",
    "feature_list = create_dummy_feature_list(48)\n",
    "# feature_list = ['Medical_Keyword_1','Medical_Keyword_2']\n",
    "# print feature_list\n",
    "\n",
    "temp = test_df[feature_list]\n",
    "# print len (temp)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dummy_feature_list(limit):\n",
    "    feature_list = ['Medical_Keyword_'+str(i+1) for i in xrange(limit)]\n",
    "    return feature_list\n",
    "#     for i in xrange(limit):\n",
    "#         feature_list.append(\"Medical_Keyowrd_\"+str(i+1))\n",
    "#     return feature_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_test_set(typeofSet):\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    test_id = test_df['Id']\n",
    "\n",
    "    test_df_categorical = test_df[feature_list]\n",
    "    test_df_discrete = test_df[discrete_feature_list]\n",
    "    test_df_dummy = test_df[dummy_feature_list]\n",
    "\n",
    "    test_df = pd.concat([test_df_categorical, test_df_discrete, test_df_dummy], axis=1)\n",
    "    features_test, total_columns_test = process_features(test_df)\n",
    "    \n",
    "    if typeofSet == \"xgboost\":\n",
    "        features_test = xgb.DMatrix(features_test, labels_test)\n",
    "    \n",
    "    return features_test,test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_file(clf,features_test,typeofSet,test_id):\n",
    "    pred = clf.predict(features_test)\n",
    "    \n",
    "    \n",
    "    if typeofSet == 'xgboost':\n",
    "        pred_df = pd.DataFrame(pred,columns=range(1,9))\n",
    "        pred_df = pred_df.apply(get_cat,axis=1)\n",
    "    else:\n",
    "        pred_df = [x+1 for x in pred]\n",
    "    \n",
    "    import csv\n",
    "    with open('%s_results.csv' % typeofSet, 'wb') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow(['Id','Response'])\n",
    "\n",
    "        for ids,label in zip(test_id,pred_df):\n",
    "            spamwriter.writerow([ids,label])\n",
    "\n",
    "        print \"file written\"\n",
    "    \n",
    "    return pred_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting process\n",
      "entered applied algorithms function\n",
      " accuracy in logistic regression is  0.498721860312\n",
      " calculated f1Score is  0.458889697996\n",
      " accuracy in SVM regression is  0.378824111487\n",
      " calculated f1Score is  0.262084094364\n",
      "accuracy in gradient boosting is 0.569967840356\n",
      "calculated f1Score in is  0.535319675051\n",
      " accuracy in logistic regression is  0.569967840356\n",
      " calculated f1Score is  0.535319675051\n",
      "accuracy in decision tree 0.441164344026\n",
      "calculated f1Score is  0.441201454145\n",
      "accuracy in random forest is 0.558423352849\n",
      "calculated f1Score in is  0.530720530689\n",
      "accuracy in random forest 0.558423352849\n",
      "calculated f1Score is  0.530720530689\n",
      " taking results from all algoorithms for boosting\n",
      "length of data frame after concatenation 60635\n",
      "no of columns in data set 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'DMatrix' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-6ed53ef2aa9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mxgboost_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgboost_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mxg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxg_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbreak_training_data_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgboost_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m xgboost_model, accuracy,f1Score = xgboost_train(xgtrain, labels_train, features_test, labels_test,\n",
      "\u001b[1;32m<ipython-input-19-9385479b3b3c>\u001b[0m in \u001b[0;36mbreak_training_data_set\u001b[1;34m(training_features, training_labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbreak_training_data_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mftrs_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlbls_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'DMatrix' has no len()"
     ]
    }
   ],
   "source": [
    "## xgboost with all the features \n",
    "print \"starting process\"\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df = train_df.fillna(-1)\n",
    "\n",
    "features=train_df.drop([\"Id\",\"Response\"],axis=1)\n",
    "labels=train_df[\"Response\"].astype(\"category\")\n",
    "labels=labels.cat.rename_categories(range(8))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "features[\"Product_Info_2\"]=le.fit_transform(features[\"Product_Info_2\"])\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = break_training_data_set(features, \n",
    "                                                                                          labels)\n",
    "models, predictions = apply_algorithms(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "print \" taking results from all algoorithms for boosting\"\n",
    "\n",
    "xgboost_df = pd.concat(pd.DataFrame(pred) for pred in predictions, axis=1)\n",
    "print \"length of data frame after concatenation\", len(xgboost_df)\n",
    "print \"no of columns in data set\", len(xgboost_df.columns)\n",
    "\n",
    "xgboost_df = xgb.DMatrix(xgboost_df)\n",
    "\n",
    "xg_train, labels_train, xg_test, labels_test = break_training_data_set(xgboost_df, labels)\n",
    "\n",
    "xgboost_model, accuracy,f1Score = xgboost_train(xgtrain, labels_train, features_test, labels_test,\n",
    "                                                                              num_class=len(labels_train.unique()))\n",
    "\n",
    "print \"starting to process test data \"\n",
    "\n",
    "test_df=pd.read_csv(\"test.csv\")\n",
    "test_df=test_df.fillna(-1)\n",
    "test_id = test_df['Id']\n",
    "features_sub=test_df.drop([\"Id\"],axis=1)\n",
    "features_sub[\"Product_Info_2\"]=le.transform(features_sub[\"Product_Info_2\"])\n",
    "model_sequence = ['logistic','svm','gradient','decisiontree','randomforest']\n",
    "\n",
    "for model,name in zip (models,model_sequence):\n",
    "    pred = write_file(model,features_sub,name,test_id)\n",
    "    test_pred = pd.concat(pred)\n",
    "    \n",
    "print \" length of test data set\", len(test_pred)\n",
    "print \"columns in test data set\", len(test_pred.columns)\n",
    "\n",
    "xgtest=xgb.DMatrix(test_pred)\n",
    "\n",
    "write_file(xgboost_model,xgtest,'xgboost') \n",
    "# write_file(clf,features_sub,'logisticregression',test_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## The best algorithm till now has been logistic regression. Boosting and random forests are underperforming. \n",
    "\n",
    "## There was an improvement in the result when categorical and discrete variables both were used. Kaggle score 0.42\n",
    "\n",
    "## The result seems to improve further on usage of categorical, discrete and dummy variables. Still to be tested\n",
    "\n",
    "## xgboost with classification,discrete and dummy variables.\n",
    "df = pd.read_csv('train.csv')\n",
    "feature_list = ['Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', \n",
    "                          'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', 'InsuredInfo_1', \n",
    "                          'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', \n",
    "                          'InsuredInfo_7', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', \n",
    "                          'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', \n",
    "                          'Family_Hist_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5',\n",
    "                          'Medical_History_6','Medical_History_7', 'Medical_History_8', 'Medical_History_9', \n",
    "                          'Medical_History_10', 'Medical_History_11','Medical_History_12', 'Medical_History_13', \n",
    "                          'Medical_History_14', 'Medical_History_16', 'Medical_History_17','Medical_History_18', \n",
    "                          'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22',\n",
    "                          'Medical_History_23', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', \n",
    "                          'Medical_History_28','Medical_History_29', 'Medical_History_30', 'Medical_History_31', \n",
    "                          'Medical_History_33', 'Medical_History_34','Medical_History_35', 'Medical_History_36', \n",
    "                          'Medical_History_37', 'Medical_History_38', 'Medical_History_39','Medical_History_40', \n",
    "                          'Medical_History_41']\n",
    "\n",
    "discrete_feature_list = ['Medical_History_1', 'Medical_History_15', 'Medical_History_24', 'Medical_History_32']\n",
    "dummy_feature_list = create_dummy_feature_list(48)\n",
    "\n",
    "train_df_categorical = df[feature_list]\n",
    "train_df_discrete = df[discrete_feature_list]\n",
    "train_df_dummy = df[dummy_feature_list]\n",
    "\n",
    "\n",
    "labels= df[\"Response\"].astype(\"category\")\n",
    "labels=labels.cat.rename_categories(range(8))\n",
    "\n",
    "\n",
    "\n",
    "train_df_categorical,total_columns = process_features(train_df_categorical)\n",
    "train_df_discrete,total_columns = process_features(train_df_discrete)\n",
    "train_df_dummy,total_columns = process_features(train_df_dummy)\n",
    "\n",
    "train_df = pd.concat([train_df_categorical, train_df_discrete, train_df_dummy],  axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = break_training_data_set(train_df, \n",
    "                                                                                          labels)\n",
    "clf = apply_algorithms(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "features_test, test_id = prepare_test_set('xgboost')\n",
    "write_file(clf,features_test,'xgboost') \n",
    "# pred = clf.predict(features_test)\n",
    "# pred_df = pd.DataFrame(pred)\n",
    "# pred_xgb = pred_df.apply(get_cat,axis=1)\n",
    "# import csv\n",
    "# with open('results.csv', 'wb') as csvfile:\n",
    "#     spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "#                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "#     spamwriter.writerow(['Id','Response'])\n",
    "\n",
    "#     for ids,label in zip(test_id,pred):\n",
    "\n",
    "#         spamwriter.writerow([ids,label])\n",
    "\n",
    "# print \"file written\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicting with the help of only continuous variables.\n",
    "\n",
    "## xgboost with continuous variables \n",
    "df = pd.read_csv('train.csv')\n",
    "train_df = df[['Product_Info_4', 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', \n",
    "               'Employment_Info_4', 'Employment_Info_6', 'Insurance_History_5', \n",
    "               'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5']]\n",
    "\n",
    "train_df = train_df.fillna(-1)\n",
    "\n",
    "# features=train_df.drop([\"Id\",\"Response\"],axis=1)\n",
    "labels=df[\"Response\"].astype(\"category\")\n",
    "labels=labels.cat.rename_categories(range(8))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "# features[\"Product_Info_2\"]=le.fit_transform(features[\"Product_Info_2\"])\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = break_training_data_set(train_df, \n",
    "                                                                                          labels)\n",
    "clf = apply_algorithms(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "df=pd.read_csv(\"test.csv\")\n",
    "test_df = df[['Product_Info_4', 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', \n",
    "               'Employment_Info_4', 'Employment_Info_6', 'Insurance_History_5', \n",
    "               'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5']]\n",
    "\n",
    "test_df=test_df.fillna(-1)\n",
    "# features_sub=test_df.drop([\"Id\"],axis=1)\n",
    "# features_sub[\"Product_Info_2\"]=le.transform(features_sub[\"Product_Info_2\"])\n",
    "\n",
    "xgtest=xgb.DMatrix(test_df)\n",
    "\n",
    "write_file(clf,xgtest,'xgboost') \n",
    "\n",
    "# labels_continuous = df['Response']\n",
    "# train_df_continuous,total_columns = process_features(train_df_continuous)\n",
    "# features_train, labels_train, features_test, labels_test = break_training_data_set(train_df_continuous, labels_continuous)\n",
    "\n",
    "# # pred_floor= perform_linear_regression(features_train,labels_train,features_test,labels_test)\n",
    "# clf = apply_algorithms(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's have some fun with data. Predicting by picking up variables  \n",
    "import collections\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# separating the features and the labels of the data set \n",
    "labels = df['Response']\n",
    "counter = collections.Counter(labels)\n",
    "total = sum(counter.values(),0)\n",
    "labels_dict = {key:val/total for key,val in counter.iteritems()}\n",
    "print labels_dict\n",
    "\n",
    "features = df.drop(['Response'],1)\n",
    "features = features.drop(['Id'],1)\n",
    "#  get indexed features\n",
    "features,total_columns = process_features(features)\n",
    "\n",
    "std_dev_list, nan_index_list = std_dev_columns(features,total_columns)\n",
    "\n",
    "# sorted list of indexes with standard deviation in reverse order \n",
    "std_dev_list.sort(key=lambda x: x[0], reverse = True)\n",
    "\n",
    "# removing columns with nan standard deviations \n",
    "features = features.drop(features.columns[nan_index_list], axis=1)\n",
    "\n",
    "top_10_std = std_dev_list[:40]\n",
    "\n",
    "top_10_index = [elem[1] for elem in top_10_std]\n",
    "\n",
    "features = prepare_dataset(features, top_10_index)\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = break_training_data_set(features, labels)\n",
    "print \" len of training data set\", len(features_train)\n",
    "print \"len of test data set\", len(features_test)\n",
    "\n",
    "clf = apply_algorithms(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "# top 10 features   ->   accuracy is 35%\n",
    "# top 20 features   ->   accuracy is 40%\n",
    "# top 30 features   ->   accuracy is 45%\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_id = test_df['Id']\n",
    "# labels_test = test_df['Response']\n",
    "# features_test = test_df.drop(['Response'],1)\n",
    "features_test,total_columns_test = process_features(test_df)\n",
    "\n",
    "features_test = prepare_dataset(features_test,top_10_index)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "import csv\n",
    "with open('results.csv', 'wb') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['Id','Response'])\n",
    "\n",
    "    for ids,label in zip(test_id,pred):\n",
    "#         spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "#                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([ids,label])\n",
    "\n",
    "# import collections\n",
    "# counter = collections.Counter(pred)\n",
    "# print counter\n",
    "# total = sum(counter.values(),0)\n",
    "# pred_dict = {key:val/total for key,val in counter.iteritems()}\n",
    "# print pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(features, top_10_index):\n",
    "    features = features[top_10_index]\n",
    "    print \"total columns \", len(features.columns)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_training_data_set(training_features, training_labels):\n",
    "    \n",
    "    msk = np.random.rand(len(training_features)) < 0.8\n",
    "    ftrs_train = training_features[msk]\n",
    "    lbls_train = training_labels[msk]\n",
    "\n",
    "    ftrs_vld = training_features[~msk]\n",
    "    lbls_vld = training_labels[~msk]\n",
    "    \n",
    "    return (ftrs_train, lbls_train, ftrs_vld, lbls_vld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_features(df_num):\n",
    "#     df_num = features.drop(['Id'],1)\n",
    "    df_num = df_num.select_dtypes(include=[np.float, np.int])\n",
    "    total_columns = len(df_num.columns)\n",
    "    df_num = df_num.ix[:,0:total_columns]\n",
    "    df_num = df_num.fillna(df_num.mean())\n",
    "    \n",
    "    return (df_num, total_columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def std_dev_columns(curr_df, total_columns):\n",
    "    \n",
    "    std_dev_list = []\n",
    "    nan_index_list = []\n",
    "\n",
    "    for i in xrange(total_columns):\n",
    "#         curr_column = curr_df[[i]].fillna(curr_df[[i]].mean()).values\n",
    "        std_dev = np.std(curr_df[[i]].values)\n",
    "        if not math.isnan(std_dev):\n",
    "            std_dev_list.append((std_dev, i))\n",
    "        else:\n",
    "            nan_index_list.append(i)\n",
    "\n",
    "    return (std_dev_list, nan_index_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_algorithms(features_train,labels_train,features_test,labels_test):\n",
    "    # applying logistic regression for classification purposes \n",
    "    print \"entered applied algorithms function\"\n",
    "    \n",
    "    predictions = []\n",
    "    models = []\n",
    "    clf, accuracy,f1Score,pred = perform_logistic_regression(features_train, labels_train, features_test, labels_test)\n",
    "    predictions.append(pred)\n",
    "    models.append(clf)\n",
    "    print \" accuracy in logistic regression is \", accuracy\n",
    "    print \" calculated f1Score is \", f1Score\n",
    "    \n",
    "    clf, accuracy,f1Score,pred = perform_svm_SVC(features_train, labels_train, features_test, labels_test)\n",
    "    predictions.append(pred)\n",
    "    models.append(clf)\n",
    "    print \" accuracy in SVM regression is \", accuracy\n",
    "    print \" calculated f1Score is \", f1Score\n",
    "    \n",
    "#     clf, accuracy,f1Score = xgboost_train(features_train, labels_train, features_test, labels_test,\n",
    "#                                                                               num_class=len(labels_train.unique()))\n",
    "#     print \" accuracy in xgboost regression is \", accuracy\n",
    "#     print \" calculated f1Score is \", f1Score\n",
    "\n",
    "    clf, accuracy,f1Score,pred = perform_gradient_boosting(features_train, labels_train, features_test, labels_test)\n",
    "    predictions.append(pred)\n",
    "    models.append(clf)\n",
    "    print \" accuracy in logistic regression is \", accuracy\n",
    "    print \" calculated f1Score is \", f1Score\n",
    "    \n",
    "    clf, accuracy,f1Score,pred = perform_decision_tree(features_train, labels_train, features_test, labels_test)\n",
    "    predictions.append(pred)\n",
    "    models.append(clf)\n",
    "    print \"accuracy in decision tree\", accuracy\n",
    "    print \"calculated f1Score is \", f1Score\n",
    "    \n",
    "    clf, accuracy,f1Score,pred = perform_random_forest(features_train, labels_train, features_test, labels_test)\n",
    "    predictions.append(pred)\n",
    "    models.append(clf)\n",
    "    print \"accuracy in random forest\", accuracy\n",
    "    print \"calculated f1Score is \", f1Score\n",
    "    \n",
    "    return (models,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_logistic_regression(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_linear_regression(features_train,labels_train,features_test,labels_test):\n",
    "#     train_df, test_df = process_features(features_train, features_test)\n",
    "\n",
    "    clf = linear_model.Lasso(alpha=0.1)\n",
    "#     training_accuracy = []\n",
    "\n",
    "#     for i in xrange(5):\n",
    "#         ftrs_train, lbls_train, ftrs_vld, lbls_vld = break_training_data_set(features_train, labels_train)\n",
    "# #         trn_df, vld_df = process_features(ftrs_train, ftrs_vld)\n",
    "    \n",
    "#         clf.fit(ftrs_train,lbls_train)\n",
    "#         pred = clf.predict(ftrs_vld)\n",
    "#         pred_floor = [int (math.floor(x)) for x in pred]\n",
    "        \n",
    "        \n",
    "#         training_accuracy.append(accuracy_score(lbls_vld, pred_floor))\n",
    "    \n",
    "#     print \" average training accuracy\", np.mean(training_accuracy)\n",
    "    clf.fit(features_train,labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    pred_floor = [int (math.floor(x)) for x in pred]\n",
    "    print \"accuracy on test set is \", accuracy_score(labels_test, pred_floor)\n",
    "    \n",
    "    return pred_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_decision_tree(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_svm_SVC(features_train, labels_train, features_test, labels_test):\n",
    "     \n",
    "    \n",
    "    clf = svm.LinearSVC()\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_gradient_boosting(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "   \n",
    "    clf = GradientBoostingClassifier(n_estimators = 40)\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    print \"accuracy in gradient boosting is\", accuracy\n",
    "    print \"calculated f1Score in is \", f1score\n",
    "    \n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_random_forest(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "#     for i in xrange(20):\n",
    "    clf = RandomForestClassifier(n_estimators = 40)\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    print \"accuracy in random forest is\", accuracy\n",
    "    print \"calculated f1Score in is \", f1score\n",
    "    \n",
    "    return (clf,accuracy,f1score,pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_operations(features_train, labels_train, features_test, labels_test,clf):\n",
    "    \n",
    "    \n",
    "#     training_accuracy = []\n",
    "#     training_f1score = []\n",
    "#     for i in xrange(5):\n",
    "#         ftrs_train, lbls_train, ftrs_vld, lbls_vld = break_training_data_set(features_train, labels_train)\n",
    "#         clf.fit(ftrs_train,lbls_train)\n",
    "#         pred = clf.predict(ftrs_vld)\n",
    "        \n",
    "#         training_accuracy.append(accuracy_score(lbls_vld, pred))\n",
    "#         training_f1score.append(f1_score(lbls_vld, pred, average = 'weighted'))\n",
    "        \n",
    "#         print \"training accuracy in round \",i+1, accuracy_score(lbls_vld, pred)\n",
    "#         print \"f1Score in round \", i+1, f1_score(lbls_vld, pred, average = 'weighted')\n",
    "\n",
    "    clf.fit(features_train,labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    \n",
    "    accuracy = accuracy_score(labels_test, pred)\n",
    "    f1score = f1_score(labels_test, pred, average = 'weighted')\n",
    "    \n",
    "    return (accuracy, f1score, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgboost_train(features_train,labels_train,features_test, labels_test, num_class):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"multi:softprob\"\n",
    "    params[\"eta\"] =  0.01\n",
    "    params[\"subsample\"] = 0.8\n",
    "    params[\"colsample_bytree\"] = 0.8\n",
    "    params[\"num_class\"]=num_class\n",
    "#     params[\"scale_pos_weight\"] = 1\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 12\n",
    "    params[\"eval_metric\"] = 'mlogloss'\n",
    "\n",
    "    plst = list(params.items())\n",
    "\n",
    "    offset = 10000\n",
    "\n",
    "    num_rounds = 500\n",
    "    \n",
    "\n",
    "    ftrs_train, lbls_train, ftrs_vld, lbls_vld = break_training_data_set(features_train, labels_train)\n",
    "        \n",
    "    xgtrain = xgb.DMatrix(ftrs_train, lbls_train)\n",
    "    xgval = xgb.DMatrix(ftrs_vld, lbls_vld)\n",
    "    \n",
    "    watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=120,verbose_eval=True)\n",
    "    \n",
    "    xgtest = xgb.DMatrix(features_test, labels_test)\n",
    "    \n",
    "    pred = model.predict(xgtest,ntree_limit=model.best_iteration)\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    pred_xgb = pred_df.apply(get_cat,axis=1)\n",
    "        \n",
    "    accuracy = accuracy_score(labels_test, pred_xgb)\n",
    "    f1score = f1_score(labels_test, pred_xgb, average = 'weighted')\n",
    "        \n",
    "    return (model,accuracy,f1score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cat(x):\n",
    "    retval=x.idxmax()\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
