{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import xgboost as xgb\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_naive_bayes(features_train, labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_logistic_regression(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_linear_regression(features_train,labels_train,features_test,labels_test):\n",
    "    \n",
    "    clf = linear_model.Lasso(alpha=0.1)\n",
    "    clf.fit(features_train,labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    pred_floor = [int (math.floor(x)) for x in pred]\n",
    "    print \"accuracy on test set is \", accuracy_score(labels_test, pred_floor)\n",
    "    \n",
    "    return pred_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_decision_tree(features_train, labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_svm_SVC(features_train, labels_train, features_test, labels_test):\n",
    "     \n",
    "    clf = svm.LinearSVC()\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_gradient_boosting(features_train, labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf = ensemble.GradientBoostingClassifier(n_estimators = len(features_train.columns))\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_random_forest(features_train, labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf = ensemble.RandomForestClassifier(n_estimators = len(features_train.columns))\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_neural_networks(features_train, labels_train, features_test, labels_test):\n",
    "    clf = BernoulliRBM(n_components=2)\n",
    "    accuracy,f1score, pred = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_operations(features_train, labels_train, features_test, labels_test,clf):\n",
    "    \n",
    "    clf.fit(features_train,labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    accuracy = accuracy_score(labels_test, pred)\n",
    "    f1score = f1_score(labels_test, pred, average = 'weighted')\n",
    "    \n",
    "    return (accuracy, f1score, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgboost_train(features_train,labels_train,features_test, labels_test, num_class):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"multi:softprob\"\n",
    "    params[\"eta\"] =  0.01\n",
    "    params[\"subsample\"] = 0.8\n",
    "    params[\"colsample_bytree\"] = 0.8\n",
    "    params[\"num_class\"]=num_class\n",
    "#     params[\"scale_pos_weight\"] = 1\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 15\n",
    "    params[\"eval_metric\"] = 'mlogloss'\n",
    "\n",
    "    plst = list(params.items())\n",
    "    offset = 10000\n",
    "    num_rounds = 500\n",
    "    \n",
    "    ftrs_train, lbls_train, ftrs_vld, lbls_vld = break_training_data_set(features_train, labels_train)\n",
    "    xgtrain = xgb.DMatrix(ftrs_train, lbls_train)\n",
    "    xgval = xgb.DMatrix(ftrs_vld, lbls_vld)\n",
    "    watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=120,verbose_eval=True)\n",
    "    \n",
    "    xgtest = xgb.DMatrix(features_test, labels_test)\n",
    "    pred = model.predict(xgtest,ntree_limit=model.best_iteration)\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    pred_xgb = pred_df.apply(get_cat,axis=1)\n",
    "        \n",
    "    accuracy = accuracy_score(labels_test, pred_xgb)\n",
    "    f1score = f1_score(labels_test, pred_xgb, average = 'weighted')\n",
    "        \n",
    "    return (model,accuracy,f1score,pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cat(x):\n",
    "    retval=x.idxmax()\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_algorithms(features_train,labels_train,features_test,labels_test):\n",
    "    # applying logistic regression for classification purposes \n",
    "    print \"entered applied algorithms function\"\n",
    "    \n",
    "    with open('algorithms_results.csv', 'wb') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        spamwriter.writerow(['Method','Accuracy','F1score'])\n",
    "        predictions = []\n",
    "        models = []\n",
    "    \n",
    "        clf, accuracy,f1Score,pred = perform_naive_bayes(features_train, labels_train, features_test, labels_test)\n",
    "        predictions.append(pred)\n",
    "        models.append(clf)\n",
    "        print \" accuracy in naive bayes is \", accuracy\n",
    "        print \" calculated f1Score is \", f1Score\n",
    "        print \"-----------------------------------------------------------------------------------------------\"\n",
    "        spamwriter.writerow(['Naive Bayes',accuracy,f1Score])\n",
    "        \n",
    "#         clf, accuracy,f1Score,pred = perform_logistic_regression(features_train, labels_train, features_test, labels_test)\n",
    "#         predictions.append(pred)\n",
    "#         models.append(clf)\n",
    "#         print \" accuracy in logistic regression is \", accuracy\n",
    "#         print \" calculated f1Score is \", f1Score\n",
    "#         print \"-----------------------------------------------------------------------------------------------\"\n",
    "#         spamwriter.writerow(['Logistic',accuracy,f1Score])\n",
    "    \n",
    "#         clf, accuracy,f1Score,pred = perform_svm_SVC(features_train, labels_train, features_test, labels_test)\n",
    "#         predictions.append(pred)\n",
    "#         models.append(clf)\n",
    "#         print \" accuracy in SVM regression is \", accuracy\n",
    "#         print \" calculated f1Score is \", f1Score\n",
    "#         print \"-----------------------------------------------------------------------------------------------\"\n",
    "#         spamwriter.writerow(['SVM',accuracy,f1Score])\n",
    "        \n",
    "#         clf, accuracy,f1Score,pred = perform_gradient_boosting(features_train, labels_train, features_test, labels_test)\n",
    "#         predictions.append(pred)\n",
    "#         models.append(clf)\n",
    "#         print \" accuracy in gradient boosting  is \", accuracy\n",
    "#         print \" calculated f1Score is \", f1Score\n",
    "#         print \"-----------------------------------------------------------------------------------------------\"\n",
    "#         spamwriter.writerow(['gradient',accuracy,f1Score])\n",
    "    \n",
    "#         clf, accuracy,f1Score,pred = perform_decision_tree(features_train, labels_train, features_test, labels_test)\n",
    "#         predictions.append(pred)\n",
    "#         models.append(clf)\n",
    "#         print \"accuracy in decision tree\", accuracy\n",
    "#         print \"calculated f1Score is \", f1Score\n",
    "#         print \"-----------------------------------------------------------------------------------------------\"  \n",
    "#         spamwriter.writerow(['decision',accuracy,f1Score])\n",
    "    \n",
    "#         clf, accuracy,f1Score,pred = perform_random_forest(features_train, labels_train, features_test, labels_test)\n",
    "#         predictions.append(pred)\n",
    "#         models.append(clf)\n",
    "#         print \"accuracy in random forest\", accuracy\n",
    "#         print \"calculated f1Score is \", f1Score\n",
    "#         print \"-----------------------------------------------------------------------------------------------\"\n",
    "#         spamwriter.writerow(['random_forest',accuracy,f1Score])\n",
    "    \n",
    "#         clf, accuracy,f1Score,pred = xgboost_train(features_train, labels_train, features_test, labels_test,\n",
    "#                                                                               num_class=len(labels_train.unique()))\n",
    "#         predictions.append(pred)\n",
    "#         models.append(clf)\n",
    "#         print \" accuracy in xgboost regression is \", accuracy\n",
    "#         print \" calculated f1Score is \", f1Score\n",
    "#         print \"-----------------------------------------------------------------------------------------------\"\n",
    "#         spamwriter.writerow(['xgboost',accuracy,f1Score])\n",
    "        \n",
    "#         clf, accuracy,f1Score,pred = perform_neural_networks(features_train, labels_train, features_test, labels_test)\n",
    "#         predictions.append(pred)\n",
    "#         models.append(clf)\n",
    "#         print \" accuracy in neural network is \", accuracy\n",
    "#         print \" calculated f1Score is \", f1Score\n",
    "#         print \"-----------------------------------------------------------------------------------------------\"\n",
    "#         spamwriter.writerow(['neural_network',accuracy,f1Score])\n",
    "    \n",
    "    return (models,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_training_data_set(training_features, training_labels):\n",
    "    \n",
    "    msk = np.random.rand(len(training_features)) < 0.8\n",
    "    ftrs_train = training_features[msk]\n",
    "    lbls_train = training_labels[msk]\n",
    "\n",
    "    ftrs_vld = training_features[~msk]\n",
    "    lbls_vld = training_labels[~msk]\n",
    "    \n",
    "    return (ftrs_train, lbls_train, ftrs_vld, lbls_vld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data_set(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    df = df.fillna(-1)\n",
    "\n",
    "    features=df.drop([\"Id\",\"Response\"],axis=1)\n",
    "    le=LabelEncoder()\n",
    "    features[\"Product_Info_2\"]=le.fit_transform(features[\"Product_Info_2\"])\n",
    "    \n",
    "    return df,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dummy_variable(series):\n",
    "    counter = collections.Counter(series)\n",
    "    print counter\n",
    "    categories = len(counter.keys())\n",
    "    columns = []\n",
    "    for val in series:\n",
    "        column = [0 for i in xrange(categories) ]\n",
    "        column[val-1] = 1\n",
    "        columns.append(column)\n",
    "    return columns,categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bernoulli_model(features_train,n_component):\n",
    "    model = BernoulliRBM(n_components=n_component).fit(features_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pca_model(features_train,n_component):\n",
    "    pca = RandomizedPCA(n_components=n_component, whiten=True).fit(features_train)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## xgboost with all the features\n",
    "def primary_evaluation_script(train_df,labels, test_df):\n",
    "    print \"starting process\"\n",
    "\n",
    "    \n",
    "    features_train, labels_train, features_test, labels_test = break_training_data_set(train_df, labels)\n",
    "    models, predictions = apply_algorithms(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "    print \"starting to process test data \"\n",
    "\n",
    "    \n",
    "#     model_sequence = ['logistic','svm','gradient','decisiontree','randomforest','xgboost']\n",
    "    model_sequence =['naivebayes']\n",
    "    predictions = []\n",
    "    for model,name in zip (models,model_sequence):\n",
    "        pred = write_file(model,test_df,name,test_id)\n",
    "        predictions.append(pred)\n",
    "        \n",
    "    print \"process completed \"\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def boost(trainFileName, testFileName):\n",
    "    print \"starting process\"\n",
    "\n",
    "    train_df, features = process_data_set(trainFileName)\n",
    "    labels=train_df[\"Response\"].astype(\"category\")\n",
    "    labels=labels.cat.rename_categories(range(8))\n",
    "\n",
    "    features_train, labels_train, features_test, labels_test = break_training_data_set(features, labels)\n",
    "    n_components = [10,20,30,40,50,60,70,80,90,100,110,120]\n",
    "    \n",
    "    while(n_components):\n",
    "        n_component = n_components[0]\n",
    "        n_components.remove(n_component)\n",
    "        \n",
    "#         model = get_bernoulli_model(features_train, n_component)\n",
    "        model = get_pca_model(features_train,n_component)\n",
    "        accuracy, f1Score, pred = boost_with_model(features_train,labels_train,features_test,labels_test,\n",
    "                                                                       model,n_component)\n",
    "        print \" accuracy with bernoulli RBM is \", accuracy\n",
    "        print \" calculated f1Score is \", f1Score\n",
    "        print \"-----------------------------------------------------------------------------------------------\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boost_with_model(features_train,labels_train,features_test,labels_test,model,n_component):\n",
    "   \n",
    "    train_data = model.transform(features_train)\n",
    "    test_data = model.transform(features_test)\n",
    "        \n",
    "        \n",
    "    clf = ensemble.RandomForestClassifier(n_estimators = n_component)\n",
    "#     clf = svm.LinearSVC()\n",
    "    clf=clf.fit(train_data,labels_train)\n",
    "    pred = clf.predict(test_data)\n",
    "        \n",
    "    accuracy = accuracy_score(labels_test, pred)\n",
    "    f1Score = f1_score(labels_test, pred, average = 'weighted')\n",
    "        \n",
    "    return (accuracy, f1Score, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_selection_withXGBoost(trainFileName):\n",
    "    print \"starting process\"\n",
    "\n",
    "    train_df, features = process_data_set(trainFileName)\n",
    "    labels=train_df[\"Response\"].astype(\"category\")\n",
    "    labels=labels.cat.rename_categories(range(8))\n",
    "\n",
    "    features_train, labels_train, features_test, labels_test = break_training_data_set(features, labels)\n",
    "    \n",
    "    xgboost_model, accuracy,f1Score,pred = xgboost_train(features_train.as_matrix(), labels_train.as_matrix(), \n",
    "                                                     features_test.as_matrix(), labels_test.as_matrix(), \n",
    "                                                         num_class= len(labels_train.unique()))\n",
    "\n",
    "    xgboost_features = xgboost_model.get_fscore()\n",
    "    \n",
    "    return xgboost_features,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boost_with_gbm(features,feature_dict):\n",
    "    \n",
    "    d_descending = sorted(feature_dict.items(), key=lambda x: (-x[1], x[0]))\n",
    "    f1Score_old = 0\n",
    "    ftrs_selected = 10\n",
    "    while True:\n",
    "        if ftrs_selected > len(features.columns):\n",
    "            break\n",
    "        top_10_descending = d_descending[1:ftrs_selected]\n",
    "        col_nos = [int(col[0][1:]) for col in top_10_descending]\n",
    "\n",
    "        new_train_data = features[col_nos]\n",
    "\n",
    "        new_features_train, new_labels_train, new_features_test, new_labels_test = break_training_data_set(new_train_data, labels)\n",
    "\n",
    "        clf, accuracy,f1Score,pred = perform_gradient_boosting(new_features_train, new_labels_train, \n",
    "                                                                           new_features_test, new_labels_test)\n",
    "\n",
    "        print \" accuracy in gradient boosting  is \", accuracy\n",
    "        print \" calculated f1Score is \", f1Score\n",
    "        print \"-----------------------------------------------------------------------------------------------\"\n",
    "    \n",
    "    \n",
    "    \n",
    "        f1Score_old = f1Score\n",
    "        ftrs_selected += 10\n",
    "    \n",
    "        if f1Score > f1Score_old:\n",
    "            test_df=pd.read_csv(\"test.csv\")\n",
    "            test_df=test_df.fillna(-1)\n",
    "            test_id = test_df['Id']\n",
    "            features_sub=test_df.drop([\"Id\"],axis=1)\n",
    "            features_sub[\"Product_Info_2\"]=le.transform(features_sub[\"Product_Info_2\"])\n",
    "            new_features_sub = features_sub[col_nos]\n",
    "            write_file(clf,new_features_sub,'gradient',test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(clf,features_test,typeofSet,test_id):\n",
    "    print \"predicting for ---->\", typeofSet\n",
    "    if typeofSet == 'xgboost':\n",
    "        xgtest=xgb.DMatrix(features_test)\n",
    "        pred = clf.predict(xgtest,ntree_limit=clf.best_iteration)\n",
    "        pred_df = pd.DataFrame(pred,columns=range(1,9))\n",
    "        pred_df = pred_df.apply(get_cat,axis=1)\n",
    "    else:\n",
    "        pred = clf.predict(features_test)\n",
    "        pred_df = [x+1 for x in pred]\n",
    "    \n",
    "    \n",
    "    with open('%s_results.csv' % typeofSet, 'wb') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow(['Id','Response'])\n",
    "\n",
    "        for ids,label in zip(test_id,pred_df):\n",
    "            spamwriter.writerow([ids,label])\n",
    "\n",
    "        print \"file written\",typeofSet\n",
    "    \n",
    "    return pred_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_graphs(dataFrame, features_of_interest):\n",
    "#     dataFrame[features_of_interest[0]].hist()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2,ncols=2)\n",
    "    axes[0].plot([0,1,2], [2,3,4])\n",
    "#     count =0\n",
    "#     for ax in axes:\n",
    "#         col_name = features_of_interest[count]\n",
    "#         ax.plot([0,1,2], [2,3,4])\n",
    "#         count +=1\n",
    "    fig.savefig('req_plots.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## methods defined below this point are specific to the problem\n",
    "def add_dummy_variable(dataset, variable_list):\n",
    "\n",
    "    print \"dimensions of dataset before processing\", dataset.shape\n",
    "    \n",
    "    categorical_df = dataset[variable_list]\n",
    "    print \"dimensions of categorical dataset \", categorical_df.shape\n",
    "    \n",
    "    dataset = dataset.drop(variable_list,1)\n",
    "    print \"dimensions after dropping categorical variables\", dataset.shape\n",
    "    print \"---------------------------------------------------------------------------------\"\n",
    "\n",
    "    dummy_df = pd.DataFrame()\n",
    "    for name in variable_list:\n",
    "        print \"processing\", name\n",
    "        series = categorical_df[name].values\n",
    "        dummy_df= dummy_df.add(pd.get_dummies(series))\n",
    "    \n",
    "#     dummy_df = pd.concat(new_df_list)\n",
    "    dataset = dataset.add(dummy_df)\n",
    "    print \"final dimensions\", dataset.shape\n",
    "    print \"---------------------------------------------------------------------------------\"\n",
    "    \n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## performing analyis with dummy variables \n",
    "def create_dummy_datasets(dataset,fileName):\n",
    "    categorical_variables = ['Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', \n",
    "                          'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', 'InsuredInfo_1', \n",
    "                          'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', \n",
    "                          'InsuredInfo_7', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', \n",
    "                          'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', \n",
    "                          'Family_Hist_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5',\n",
    "                          'Medical_History_6','Medical_History_7', 'Medical_History_8', 'Medical_History_9', \n",
    "                          'Medical_History_10', 'Medical_History_11','Medical_History_12', 'Medical_History_13', \n",
    "                          'Medical_History_14', 'Medical_History_16', 'Medical_History_17','Medical_History_18', \n",
    "                          'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22',\n",
    "                          'Medical_History_23', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', \n",
    "                          'Medical_History_28','Medical_History_29', 'Medical_History_30', 'Medical_History_31', \n",
    "                          'Medical_History_33', 'Medical_History_34','Medical_History_35', 'Medical_History_36', \n",
    "                          'Medical_History_37', 'Medical_History_38', 'Medical_History_39','Medical_History_40', \n",
    "                          'Medical_History_41']\n",
    "\n",
    "    features = add_dummy_variable(dataset,categorical_variables)\n",
    "    features = features.fillna(-1)\n",
    "\n",
    "    \n",
    "    features.to_csv(fileName+'_dataset.csv', sep =',')\n",
    "    print \"file written\", fileName\n",
    "    print \"-----------------------------------------------------------------------------\"\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of training data (59381, 128)\n",
      "dimension of test data (19765, 127)\n",
      "starting process\n",
      "entered applied algorithms function\n",
      " accuracy in naive bayes is  0.3445069942\n",
      " calculated f1Score is  0.303525010061\n",
      "-----------------------------------------------------------------------------------------------\n",
      "starting to process test data \n",
      "predicting for ----> naivebayes\n",
      "file written naivebayes\n",
      "process completed \n"
     ]
    }
   ],
   "source": [
    "# Run this function to run the code \n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "print \"dimensions of training data\", train_df.shape\n",
    "\n",
    "train_df = train_df.fillna(-1)\n",
    "features_train=train_df.drop([\"Id\",\"Response\"],axis=1)\n",
    "le=LabelEncoder()\n",
    "features_train[\"Product_Info_2\"]=le.fit_transform(features_train[\"Product_Info_2\"])\n",
    "    \n",
    "labels=train_df[\"Response\"].astype(\"category\")\n",
    "labels=labels.cat.rename_categories(range(8))\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print \"dimension of test data\", test_df.shape\n",
    "\n",
    "test_id = test_df['Id']\n",
    "test_df=test_df.fillna(-1)\n",
    "features_test=test_df.drop([\"Id\"],axis=1)\n",
    "features_test[\"Product_Info_2\"]=le.transform(features_test[\"Product_Info_2\"])\n",
    "\n",
    "\n",
    "predictions = primary_evaluation_script(features_train,labels,features_test)\n",
    "\n",
    "# pick_modes(predictions)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_modes(predictions):\n",
    "    new_features = pd.DataFrame(pd.Series(pred) for pred in predictions)\n",
    "    new_features = new_features.transpose()\n",
    "\n",
    "# Taking mode of all predictions \n",
    "    pred_df= [max(row) for row in new_features.as_matrix()]\n",
    "    print len(pred_df)\n",
    "\n",
    "    with open('modes_results.csv', 'wb') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow(['Id','Response'])\n",
    "\n",
    "        for ids,label in zip(test_id,pred_df):\n",
    "            spamwriter.writerow([ids,label])\n",
    "\n",
    "    print \"file written modes_results.csv\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Product_Info_1  Product_Info_3  Product_Info_5  Product_Info_6  \\\n",
      "count    59381.000000    59381.000000    59381.000000    59381.000000   \n",
      "mean         1.026355       24.415655        2.006955        2.673599   \n",
      "std          0.160191        5.072885        0.083107        0.739103   \n",
      "min          1.000000        1.000000        2.000000        1.000000   \n",
      "25%          1.000000       26.000000        2.000000        3.000000   \n",
      "50%          1.000000       26.000000        2.000000        3.000000   \n",
      "75%          1.000000       26.000000        2.000000        3.000000   \n",
      "max          2.000000       38.000000        3.000000        3.000000   \n",
      "\n",
      "       Product_Info_7  \n",
      "count    59381.000000  \n",
      "mean         1.043583  \n",
      "std          0.291949  \n",
      "min          1.000000  \n",
      "25%          1.000000  \n",
      "50%          1.000000  \n",
      "75%          1.000000  \n",
      "max          3.000000  \n",
      "       Employment_Info_2  Employment_Info_3  Employment_Info_5\n",
      "count       59381.000000       59381.000000       59381.000000\n",
      "mean            8.641821           1.300904           2.142958\n",
      "std             4.227082           0.715034           0.350033\n",
      "min             1.000000           1.000000           2.000000\n",
      "25%             9.000000           1.000000           2.000000\n",
      "50%             9.000000           1.000000           2.000000\n",
      "75%             9.000000           1.000000           2.000000\n",
      "max            38.000000           3.000000           3.000000\n",
      "       InsuredInfo_1  InsuredInfo_2  InsuredInfo_3  InsuredInfo_4  \\\n",
      "count   59381.000000   59381.000000   59381.000000   59381.000000   \n",
      "mean        1.209326       2.007427       5.835840       2.883666   \n",
      "std         0.417939       0.085858       2.674536       0.320627   \n",
      "min         1.000000       2.000000       1.000000       2.000000   \n",
      "25%         1.000000       2.000000       3.000000       3.000000   \n",
      "50%         1.000000       2.000000       6.000000       3.000000   \n",
      "75%         1.000000       2.000000       8.000000       3.000000   \n",
      "max         3.000000       3.000000      11.000000       3.000000   \n",
      "\n",
      "       InsuredInfo_5  InsuredInfo_6  InsuredInfo_7  \n",
      "count   59381.000000   59381.000000   59381.000000  \n",
      "mean        1.027180       1.409188       1.038531  \n",
      "std         0.231566       0.491688       0.274915  \n",
      "min         1.000000       1.000000       1.000000  \n",
      "25%         1.000000       1.000000       1.000000  \n",
      "50%         1.000000       1.000000       1.000000  \n",
      "75%         1.000000       2.000000       1.000000  \n",
      "max         3.000000       2.000000       3.000000  \n",
      "       Insurance_History_1  Insurance_History_2  Insurance_History_3  \\\n",
      "count         59381.000000         59381.000000         59381.000000   \n",
      "mean              1.727606             1.055792             2.146983   \n",
      "std               0.445195             0.329328             0.989139   \n",
      "min               1.000000             1.000000             1.000000   \n",
      "25%               1.000000             1.000000             1.000000   \n",
      "50%               2.000000             1.000000             3.000000   \n",
      "75%               2.000000             1.000000             3.000000   \n",
      "max               2.000000             3.000000             3.000000   \n",
      "\n",
      "       Insurance_History_4  Insurance_History_7  Insurance_History_8  \\\n",
      "count         59381.000000         59381.000000         59381.000000   \n",
      "mean              1.958707             1.901989             2.048484   \n",
      "std               0.945739             0.971223             0.755149   \n",
      "min               1.000000             1.000000             1.000000   \n",
      "25%               1.000000             1.000000             1.000000   \n",
      "50%               2.000000             1.000000             2.000000   \n",
      "75%               3.000000             3.000000             3.000000   \n",
      "max               3.000000             3.000000             3.000000   \n",
      "\n",
      "       Insurance_History_9  \n",
      "count         59381.000000  \n",
      "mean              2.419360  \n",
      "std               0.509577  \n",
      "min               1.000000  \n",
      "25%               2.000000  \n",
      "50%               2.000000  \n",
      "75%               3.000000  \n",
      "max               3.000000  \n",
      "       Medical_History_2  Medical_History_3  Medical_History_4  \\\n",
      "count       59381.000000       59381.000000       59381.000000   \n",
      "mean          253.987100           2.102171           1.654873   \n",
      "std           178.621154           0.303098           0.475414   \n",
      "min             1.000000           1.000000           1.000000   \n",
      "25%           112.000000           2.000000           1.000000   \n",
      "50%           162.000000           2.000000           2.000000   \n",
      "75%           418.000000           2.000000           2.000000   \n",
      "max           648.000000           3.000000           2.000000   \n",
      "\n",
      "       Medical_History_5  Medical_History_6  Medical_History_7  \\\n",
      "count       59381.000000       59381.000000       59381.000000   \n",
      "mean            1.007359           2.889897           2.012277   \n",
      "std             0.085864           0.456128           0.172360   \n",
      "min             1.000000           1.000000           1.000000   \n",
      "25%             1.000000           3.000000           2.000000   \n",
      "50%             1.000000           3.000000           2.000000   \n",
      "75%             1.000000           3.000000           2.000000   \n",
      "max             3.000000           3.000000           3.000000   \n",
      "\n",
      "       Medical_History_8  Medical_History_9  Medical_History_10  \\\n",
      "count       59381.000000       59381.000000          557.000000   \n",
      "mean            2.044088           1.769943          141.118492   \n",
      "std             0.291353           0.421032          107.759559   \n",
      "min             1.000000           1.000000            0.000000   \n",
      "25%             2.000000           2.000000            8.000000   \n",
      "50%             2.000000           2.000000          229.000000   \n",
      "75%             2.000000           2.000000          240.000000   \n",
      "max             3.000000           3.000000          240.000000   \n",
      "\n",
      "       Medical_History_11         ...          Medical_History_31  \\\n",
      "count        59381.000000         ...                59381.000000   \n",
      "mean             2.993836         ...                    2.985265   \n",
      "std              0.095340         ...                    0.170989   \n",
      "min              1.000000         ...                    1.000000   \n",
      "25%              3.000000         ...                    3.000000   \n",
      "50%              3.000000         ...                    3.000000   \n",
      "75%              3.000000         ...                    3.000000   \n",
      "max              3.000000         ...                    3.000000   \n",
      "\n",
      "       Medical_History_33  Medical_History_34  Medical_History_35  \\\n",
      "count        59381.000000        59381.000000        59381.000000   \n",
      "mean             2.804618            2.689076            1.002055   \n",
      "std              0.593798            0.724661            0.063806   \n",
      "min              1.000000            1.000000            1.000000   \n",
      "25%              3.000000            3.000000            1.000000   \n",
      "50%              3.000000            3.000000            1.000000   \n",
      "75%              3.000000            3.000000            1.000000   \n",
      "max              3.000000            3.000000            3.000000   \n",
      "\n",
      "       Medical_History_36  Medical_History_37  Medical_History_38  \\\n",
      "count        59381.000000        59381.000000        59381.000000   \n",
      "mean             2.179468            1.938398            1.004850   \n",
      "std              0.412633            0.240574            0.069474   \n",
      "min              1.000000            1.000000            1.000000   \n",
      "25%              2.000000            2.000000            1.000000   \n",
      "50%              2.000000            2.000000            1.000000   \n",
      "75%              2.000000            2.000000            1.000000   \n",
      "max              3.000000            3.000000            2.000000   \n",
      "\n",
      "       Medical_History_39  Medical_History_40  Medical_History_41  \n",
      "count        59381.000000        59381.000000        59381.000000  \n",
      "mean             2.830720            2.967599            1.641064  \n",
      "std              0.556665            0.252427            0.933361  \n",
      "min              1.000000            1.000000            1.000000  \n",
      "25%              3.000000            3.000000            1.000000  \n",
      "50%              3.000000            3.000000            1.000000  \n",
      "75%              3.000000            3.000000            3.000000  \n",
      "max              3.000000            3.000000            3.000000  \n",
      "\n",
      "[8 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "# labels = ['Ht','Ins_Age','Wt','BMI']\n",
    "# for label in labels:\n",
    "#     ylabels = df[label]\n",
    "#     xlabels = [0.0,0.2,0.4,0.6,0.8,1.0]\n",
    "#     plt.hist(ylabels, 50, facecolor='b', alpha=0.7)\n",
    "#     plt.xlabel('Normalized '+label)\n",
    "#     plt.ylabel('Counts')\n",
    "#     plt.title('Distribution of '+ label)\n",
    "#     plt.savefig('../images/'+label+'.jpeg')\n",
    "#     plt.close()\n",
    "\n",
    "categorical_variables = ['Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', \n",
    "                          'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', 'InsuredInfo_1', \n",
    "                          'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', \n",
    "                          'InsuredInfo_7', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', \n",
    "                          'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', \n",
    "                          'Family_Hist_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5',\n",
    "                          'Medical_History_6','Medical_History_7', 'Medical_History_8', 'Medical_History_9', \n",
    "                          'Medical_History_10', 'Medical_History_11','Medical_History_12', 'Medical_History_13', \n",
    "                          'Medical_History_14', 'Medical_History_16', 'Medical_History_17','Medical_History_18', \n",
    "                          'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22',\n",
    "                          'Medical_History_23', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', \n",
    "                          'Medical_History_28','Medical_History_29', 'Medical_History_30', 'Medical_History_31', \n",
    "                          'Medical_History_33', 'Medical_History_34','Medical_History_35', 'Medical_History_36', \n",
    "                          'Medical_History_37', 'Medical_History_38', 'Medical_History_39','Medical_History_40', \n",
    "                          'Medical_History_41']\n",
    "\n",
    "prod_info_var = ['Product_Info_1', 'Product_Info_3','Product_Info_5', 'Product_Info_6',\n",
    "                 'Product_Info_7']\n",
    "product_info = df[prod_info_var]\n",
    "print product_info.describe()\n",
    "\n",
    "emp_info_var = ['Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5']\n",
    "emp_info = df[emp_info_var]\n",
    "print emp_info.describe()\n",
    "\n",
    "ins_info_var = ['InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', \n",
    "                          'InsuredInfo_7']\n",
    "ins_info = df[ins_info_var]\n",
    "print ins_info.describe()\n",
    "\n",
    "ins_hist_var = ['Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', \n",
    "                          'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9']\n",
    "ins_hist = df[ins_hist_var]\n",
    "print ins_hist.describe()\n",
    "\n",
    "med_hist_var = ['Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5',\n",
    "                          'Medical_History_6','Medical_History_7', 'Medical_History_8', 'Medical_History_9', \n",
    "                          'Medical_History_10', 'Medical_History_11','Medical_History_12', 'Medical_History_13', \n",
    "                          'Medical_History_14', 'Medical_History_16', 'Medical_History_17','Medical_History_18', \n",
    "                          'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22',\n",
    "                          'Medical_History_23', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', \n",
    "                          'Medical_History_28','Medical_History_29', 'Medical_History_30', 'Medical_History_31', \n",
    "                          'Medical_History_33', 'Medical_History_34','Medical_History_35', 'Medical_History_36', \n",
    "                          'Medical_History_37', 'Medical_History_38', 'Medical_History_39','Medical_History_40', \n",
    "                          'Medical_History_41']\n",
    "med_hist= df[med_hist_var]\n",
    "print med_hist.describe()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# df.hist(column = 'Ht', figsize = (8,8), color = \"blue\", bins = 50).savefig('/images/plot_ht.jpeg')\n",
    "\n",
    "# fig = plot_Ht.get_figure()\n",
    "# fig.savefig('/images/plot_Ht.jpeg')\n",
    "# df['Ht'].plot(kind = 'density', figsize =(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plotting pie chart distribution of labels of all results tried. \n",
    "fileNames = ['decisiontree_results.csv','randomforest_results.csv','svm_results.csv',\n",
    "            'logistic_results.csv','gradient_results.csv','xgboost_results.csv']\n",
    "df = pd.read_csv('train.csv')\n",
    "initial_distribution = df['Response']\n",
    "counter = collections.Counter(initial_distribution)\n",
    "initial_frac = [val for key,val in counter.iteritems()]\n",
    "\n",
    "for name in fileNames:\n",
    "    content = name.split(\"_\")\n",
    "    plot_results_pie_chart(name,content[0]+\"_label_distribution.jpeg\",content[0]+\" labels\",initial_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pie_chart(labels,fracs,fileName,title,initial_frac):\n",
    "    explode= (0, 0, 0, 0, 0, 0, 0, 0.05)\n",
    "    fig,(ax1,ax2) = plt.subplots(1,2)\n",
    "    ax1.pie(fracs,explode=explode, labels=labels,\n",
    "                autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax2.pie(initial_frac,explode=explode, labels=labels,\n",
    "                autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax1.set_title(title, bbox={'facecolor':'0.8', 'pad':5})\n",
    "    ax2.set_title('training labels', bbox={'facecolor':'0.8', 'pad':5})\n",
    "#     fig.title(title, bbox={'facecolor':'0.8', 'pad':5})\n",
    "    fig.savefig(fileName)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results_pie_chart(fileName,imageName,title,initial_frac):\n",
    "    with open(fileName, 'rb') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        response = [row[1] for row in spamreader ]\n",
    "    response= response[1:]\n",
    "    counter = collections.Counter(response)\n",
    "    labels = [x+1 for x in xrange(8)]\n",
    "    fracs = [val for key,val in counter.iteritems()]\n",
    "    plot_pie_chart(labels,fracs,'../images/'+imageName,title,initial_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_features(df_num):\n",
    "#     df_num = features.drop(['Id'],1)\n",
    "    df_num = df_num.select_dtypes(include=[np.float, np.int])\n",
    "    total_columns = len(df_num.columns)\n",
    "    df_num = df_num.ix[:,0:total_columns]\n",
    "    df_num = df_num.fillna(df_num.mean())\n",
    "    \n",
    "    return (df_num, total_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plotting some graphs with the result files \n",
    "\n",
    "df = pd.read_csv('gbm_accu_ftr_variation.csv')\n",
    "feature_count = df['feature']\n",
    "accuracy = df['accuracy']\n",
    "f1Score = df['f1Score']\n",
    "\n",
    "fig, ax = plt.subplots()  # create figure & 1 axis\n",
    "ax.plot(feature_count,accuracy,'g+',label='accuracy vs features')\n",
    "ax.plot(feature_count, f1Score,'bs', label = 'f1Score vs features')\n",
    "ax.legend(loc=4)\n",
    "ax.set_xlabel('features used for prediction')\n",
    "ax.set_ylabel('scores')\n",
    "ax.set_title('gradient boosting by feature selection from xgboost')\n",
    "fig.show()\n",
    "fig.savefig('gbm_accu_ftr_variation.png')   # save the figure to file\n",
    "\n",
    "plt.close(fig)    # close the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('method_accu_f1Score.csv')\n",
    "methods = df['Method']\n",
    "accuracy = df['accuracy']\n",
    "f1Score = df['f1Score']\n",
    "\n",
    "ax.set_color_cycle(['red', 'blue', 'yellow','orange','green','black'])\n",
    "symbols =['-','+','^','*','!','/']\n",
    "fig, ax = plt.subplots()\n",
    "for i in xrange(len(accuracy)):\n",
    "    ax.plot(accuracy[i],symbols[i],label= methods[i])\n",
    "#     ax.plot(f1Score[i],label=methods[i])\n",
    "\n",
    "ax.legend(loc='best')\n",
    "fig.show()\n",
    "fig.savefig('method_accu_f1Score.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
