{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_39</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.144667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0   1               1             D3              26        0.487179   \n",
       "1   3               1             A2              26        0.076923   \n",
       "2   4               1             D3              26        0.144667   \n",
       "3   9               1             A1              26        0.151709   \n",
       "4  12               1             A1              26        0.076923   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n",
       "0               2               3               1  0.611940  0.781818   \n",
       "1               2               3               1  0.626866  0.727273   \n",
       "2               2               3               1  0.582090  0.709091   \n",
       "3               2               1               1  0.522388  0.654545   \n",
       "4               2               3               1  0.298507  0.672727   \n",
       "\n",
       "          ...          Medical_Keyword_39  Medical_Keyword_40  \\\n",
       "0         ...                           0                   0   \n",
       "1         ...                           0                   0   \n",
       "2         ...                           0                   0   \n",
       "3         ...                           0                   0   \n",
       "4         ...                           0                   0   \n",
       "\n",
       "   Medical_Keyword_41  Medical_Keyword_42  Medical_Keyword_43  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_44  Medical_Keyword_45  Medical_Keyword_46  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_47  Medical_Keyword_48  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   1                   1  \n",
       "4                   0                   0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv',delimiter=',', encoding=\"utf-8-sig\")\n",
    "\n",
    "feature_list = create_dummy_feature_list(48)\n",
    "# feature_list = ['Medical_Keyword_1','Medical_Keyword_2']\n",
    "# print feature_list\n",
    "\n",
    "temp = test_df[feature_list]\n",
    "# print len (temp)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dummy_feature_list(limit):\n",
    "    feature_list = ['Medical_Keyword_'+str(i+1) for i in xrange(limit)]\n",
    "    return feature_list\n",
    "#     for i in xrange(limit):\n",
    "#         feature_list.append(\"Medical_Keyowrd_\"+str(i+1))\n",
    "#     return feature_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " length of training data from feature_list 59381\n",
      " columns in feature_list 61\n",
      "length of discrete training data  59381\n",
      "columns in discrete feature list 4\n",
      "length of dummy training data  59381\n",
      "columns in discrete feature list 48\n",
      "length of labels 59381\n",
      " length of final training data set 59381\n",
      "columns in final training data set 112\n",
      " length of training features 47541\n",
      "length of labels 47541\n",
      " accuracy in logistic regression is  0.469172297297\n",
      " calculated f1Score is  0.409115428467\n"
     ]
    }
   ],
   "source": [
    "## The best algorithm till now has been logistic regression. Boosting and random forests are underperforming. \n",
    "\n",
    "## There was an improvement in the result when categorical and discrete variables both were used. Kaggle score 0.42\n",
    "\n",
    "## The result seems to improve further on usage of categorical, discrete and dummy variables. Still to be tested\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "feature_list = ['Product_Info_1', 'Product_Info_2', 'Product_Info_3', 'Product_Info_5', 'Product_Info_6', \n",
    "                          'Product_Info_7', 'Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', 'InsuredInfo_1', \n",
    "                          'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', \n",
    "                          'InsuredInfo_7', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', \n",
    "                          'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', \n",
    "                          'Family_Hist_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5',\n",
    "                          'Medical_History_6','Medical_History_7', 'Medical_History_8', 'Medical_History_9', \n",
    "                          'Medical_History_10', 'Medical_History_11','Medical_History_12', 'Medical_History_13', \n",
    "                          'Medical_History_14', 'Medical_History_16', 'Medical_History_17','Medical_History_18', \n",
    "                          'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22',\n",
    "                          'Medical_History_23', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', \n",
    "                          'Medical_History_28','Medical_History_29', 'Medical_History_30', 'Medical_History_31', \n",
    "                          'Medical_History_33', 'Medical_History_34','Medical_History_35', 'Medical_History_36', \n",
    "                          'Medical_History_37', 'Medical_History_38', 'Medical_History_39','Medical_History_40', \n",
    "                          'Medical_History_41']\n",
    "\n",
    "discrete_feature_list = ['Medical_History_1', 'Medical_History_15', 'Medical_History_24', 'Medical_History_32']\n",
    "dummy_feature_list = create_dummy_feature_list(48)\n",
    "\n",
    "train_df_categorical = df[feature_list]\n",
    "train_df_discrete = df[discrete_feature_list]\n",
    "train_df_dummy = df[dummy_feature_list]\n",
    "\n",
    "print \" length of training data from feature_list\", len( train_df_categorical )\n",
    "print \" columns in feature_list\", len(train_df_categorical.columns)\n",
    "\n",
    "print \"length of discrete training data \", len( train_df_discrete )\n",
    "print \"columns in discrete feature list\", len(train_df_discrete.columns)\n",
    "\n",
    "print \"length of dummy training data \", len( train_df_dummy )\n",
    "print \"columns in discrete feature list\", len(train_df_dummy.columns)\n",
    "\n",
    "labels = df['Response']\n",
    "\n",
    "print \"length of labels\", len( labels )\n",
    "\n",
    "train_df_categorical,total_columns = process_features(train_df_categorical)\n",
    "train_df_discrete,total_columns = process_features(train_df_discrete)\n",
    "train_df_dummy,total_columns = process_features(train_df_dummy)\n",
    "\n",
    "train_df = pd.concat([train_df_categorical, train_df_discrete, train_df_dummy],  axis=1)\n",
    "\n",
    "\n",
    "print \" length of final training data set\", len(train_df)\n",
    "print \"columns in final training data set\", len(train_df.columns)\n",
    "\n",
    "# features_train, labels_train, features_test, labels_test = break_training_data_set(train_df_categorical, \n",
    "#                                                                                             labels)\n",
    "\n",
    "# features_train, labels_train, features_test, labels_test = break_training_data_set(train_df_discrete, \n",
    "#                                                                                           labels)\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = break_training_data_set(train_df, \n",
    "                                                                                          labels)\n",
    "\n",
    "# features_train = pd.concat([features_train_categorical,features_train_discrete])\n",
    "# features_test = pd.concat([features_test_categorical,features_test_discrete])\n",
    "\n",
    "print \" length of training features\", len(features_train)\n",
    "print \"length of labels\", len(labels_train)\n",
    "\n",
    "clf = apply_algorithms(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_id = test_df['Id']\n",
    "\n",
    "test_df_categorical = test_df[feature_list]\n",
    "test_df_discrete = test_df[discrete_feature_list]\n",
    "test_df_dummy = test_df[dummy_feature_list]\n",
    "\n",
    "test_df = pd.concat([test_df_categorical, test_df_discrete, test_df_dummy], axis=1)\n",
    "\n",
    "# # labels_test = test_df['Response']\n",
    "# # features_test = test_df.drop(['Response'],1)\n",
    "\n",
    "# # features_test_categorical,total_columns_test = process_features(test_df_categorical)\n",
    "# # features_test_discrete,total_columns_test = process_features(test_df_discrete)\n",
    "\n",
    "features_test, total_columns_test = process_features(test_df)\n",
    "\n",
    "# # features_test = pd.concat([features_test_categorical, features_test_discrete])\n",
    "\n",
    "# # features_test = prepare_dataset(features_test,top_10_index)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "import csv\n",
    "with open('results.csv', 'wb') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['Id','Response'])\n",
    "\n",
    "    for ids,label in zip(test_id,pred):\n",
    "#         spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "#                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([ids,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicting with the help of only continuous variables.\n",
    "df = pd.read_csv('train.csv')\n",
    "train_df_continuous = df[['Product_Info_4', 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', \n",
    "               'Employment_Info_4', 'Employment_Info_6', 'Insurance_History_5', \n",
    "               'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5']]\n",
    "labels_continuous = df['Response']\n",
    "train_df_continuous,total_columns = process_features(train_df_continuous)\n",
    "features_train, labels_train, features_test, labels_test = break_training_data_set(train_df_continuous, labels_continuous)\n",
    "\n",
    "# pred_floor= perform_linear_regression(features_train,labels_train,features_test,labels_test)\n",
    "clf = apply_algorithms(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.10452838450009262, 2: 0.110338323706236, 3: 0.017059328741516645, 4: 0.02404809619238477, 5: 0.0914770717906401, 6: 0.1891682524713292, 7: 0.13517791886293595, 8: 0.3282026237348647}\n",
      "total columns  40\n",
      " len of training data set 47493\n",
      "len of test data set 11888\n",
      " accuracy in logistic regression is  0.443472409152\n",
      " calculated f1Score is  0.376379563369\n",
      "total columns  40\n"
     ]
    }
   ],
   "source": [
    "# Let's have some fun with data. Predicting by picking up variables  \n",
    "import collections\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# separating the features and the labels of the data set \n",
    "labels = df['Response']\n",
    "counter = collections.Counter(labels)\n",
    "total = sum(counter.values(),0)\n",
    "labels_dict = {key:val/total for key,val in counter.iteritems()}\n",
    "print labels_dict\n",
    "\n",
    "features = df.drop(['Response'],1)\n",
    "features = features.drop(['Id'],1)\n",
    "#  get indexed features\n",
    "features,total_columns = process_features(features)\n",
    "\n",
    "std_dev_list, nan_index_list = std_dev_columns(features,total_columns)\n",
    "\n",
    "# sorted list of indexes with standard deviation in reverse order \n",
    "std_dev_list.sort(key=lambda x: x[0], reverse = True)\n",
    "\n",
    "# removing columns with nan standard deviations \n",
    "features = features.drop(features.columns[nan_index_list], axis=1)\n",
    "\n",
    "top_10_std = std_dev_list[:40]\n",
    "\n",
    "top_10_index = [elem[1] for elem in top_10_std]\n",
    "\n",
    "features = prepare_dataset(features, top_10_index)\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = break_training_data_set(features, labels)\n",
    "print \" len of training data set\", len(features_train)\n",
    "print \"len of test data set\", len(features_test)\n",
    "\n",
    "clf = apply_algorithms(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "# top 10 features   ->   accuracy is 35%\n",
    "# top 20 features   ->   accuracy is 40%\n",
    "# top 30 features   ->   accuracy is 45%\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_id = test_df['Id']\n",
    "# labels_test = test_df['Response']\n",
    "# features_test = test_df.drop(['Response'],1)\n",
    "features_test,total_columns_test = process_features(test_df)\n",
    "\n",
    "features_test = prepare_dataset(features_test,top_10_index)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "import csv\n",
    "with open('results.csv', 'wb') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['Id','Response'])\n",
    "\n",
    "    for ids,label in zip(test_id,pred):\n",
    "#         spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "#                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([ids,label])\n",
    "\n",
    "# import collections\n",
    "# counter = collections.Counter(pred)\n",
    "# print counter\n",
    "# total = sum(counter.values(),0)\n",
    "# pred_dict = {key:val/total for key,val in counter.iteritems()}\n",
    "# print pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(features, top_10_index):\n",
    "    features = features[top_10_index]\n",
    "    print \"total columns \", len(features.columns)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_training_data_set(training_features, training_labels):\n",
    "    \n",
    "    msk = np.random.rand(len(training_features)) < 0.8\n",
    "    ftrs_train = training_features[msk]\n",
    "    lbls_train = training_labels[msk]\n",
    "\n",
    "    ftrs_vld = training_features[~msk]\n",
    "    lbls_vld = training_labels[~msk]\n",
    "    \n",
    "    return (ftrs_train, lbls_train, ftrs_vld, lbls_vld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_features(df_num):\n",
    "#     df_num = features.drop(['Id'],1)\n",
    "    df_num = df_num.select_dtypes(include=[np.float, np.int])\n",
    "    total_columns = len(df_num.columns)\n",
    "    df_num = df_num.ix[:,0:total_columns]\n",
    "    df_num = df_num.fillna(df_num.mean())\n",
    "    \n",
    "    return (df_num, total_columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def std_dev_columns(curr_df, total_columns):\n",
    "    \n",
    "    std_dev_list = []\n",
    "    nan_index_list = []\n",
    "\n",
    "    for i in xrange(total_columns):\n",
    "#         curr_column = curr_df[[i]].fillna(curr_df[[i]].mean()).values\n",
    "        std_dev = np.std(curr_df[[i]].values)\n",
    "        if not math.isnan(std_dev):\n",
    "            std_dev_list.append((std_dev, i))\n",
    "        else:\n",
    "            nan_index_list.append(i)\n",
    "\n",
    "    return (std_dev_list, nan_index_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_algorithms(features_train,labels_train,features_test,labels_test):\n",
    "    # applying logistic regression for classification purposes \n",
    "    clf, accuracy,f1Score = perform_logistic_regression(features_train, labels_train, features_test, labels_test)\n",
    "    print \" accuracy in logistic regression is \", accuracy\n",
    "    print \" calculated f1Score is \", f1Score\n",
    "    \n",
    "#     clf, accuracy,f1Score = perform_gradient_boosting(features_train, labels_train, features_test, labels_test)\n",
    "#     print \" accuracy in logistic regression is \", accuracy\n",
    "#     print \" calculated f1Score is \", f1Score\n",
    "    \n",
    "#     clf, accuracy,f1Score = perform_decision_tree(features_train, labels_train, features_test, labels_test)\n",
    "#     print \"accuracy in decision tree\", accuracy\n",
    "#     print \"calculated f1Score is \", f1Score\n",
    "    \n",
    "#     clf, accuracy,f1Score = perform_random_forest(features_train, labels_train, features_test, labels_test)\n",
    "#     print \"accuracy in random forest\", accuracy\n",
    "#     print \"calculated f1Score is \", f1Score\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_logistic_regression(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    accuracy, f1score = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_linear_regression(features_train,labels_train,features_test,labels_test):\n",
    "#     train_df, test_df = process_features(features_train, features_test)\n",
    "\n",
    "    clf = linear_model.Lasso(alpha=0.1)\n",
    "    training_accuracy = []\n",
    "\n",
    "    for i in xrange(5):\n",
    "        ftrs_train, lbls_train, ftrs_vld, lbls_vld = break_training_data_set(features_train, labels_train)\n",
    "#         trn_df, vld_df = process_features(ftrs_train, ftrs_vld)\n",
    "    \n",
    "        clf.fit(ftrs_train,lbls_train)\n",
    "        pred = clf.predict(ftrs_vld)\n",
    "        pred_floor = [int (math.floor(x)) for x in pred]\n",
    "\n",
    "        training_accuracy.append(accuracy_score(lbls_vld, pred_floor))\n",
    "    \n",
    "    print \" average training accuracy\", np.mean(training_accuracy)\n",
    "    clf.fit(features_train,labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    pred_floor = [int (math.floor(x)) for x in pred]\n",
    "    print \"accuracy on test set is \", accuracy_score(labels_test, pred_floor)\n",
    "    \n",
    "    return pred_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_decision_tree(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    accuracy,f1score = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "    return (clf,accuracy,f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_gradient_boosting(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    for i in xrange(20):\n",
    "        clf = GradientBoostingClassifier(n_estimators = i+1)\n",
    "        accuracy,f1score = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "        print \"accuracy in gradient boosting  in \",i+1, \" th round is\", accuracy\n",
    "        print \"calculated f1Score in\", i+1, \" th round is \", f1score\n",
    "    \n",
    "    return (clf,accuracy,f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_random_forest(features_train, labels_train, features_test, labels_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    for i in xrange(20):\n",
    "        clf = RandomForestClassifier(n_estimators = i+1)\n",
    "        accuracy,f1score = perform_operations(features_train, labels_train, features_test, labels_test,clf)\n",
    "        print \"accuracy in random forest in \",i+1, \" th round is\", accuracy\n",
    "        print \"calculated f1Score in\", i+1, \" th round is \", f1score\n",
    "    \n",
    "    return (clf,accuracy,f1score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_operations(features_train, labels_train, features_test, labels_test,clf):\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    training_accuracy = []\n",
    "    training_f1score = []\n",
    "    for i in xrange(5):\n",
    "        ftrs_train, lbls_train, ftrs_vld, lbls_vld = break_training_data_set(features_train, labels_train)\n",
    "#         trn_df, vld_df = process_features(ftrs_train, ftrs_vld)\n",
    "    \n",
    "        clf.fit(ftrs_train,lbls_train)\n",
    "        pred = clf.predict(ftrs_vld)\n",
    "#         pred_floor = [int (math.floor(x)) for x in pred]\n",
    "\n",
    "        training_accuracy.append(accuracy_score(lbls_vld, pred))\n",
    "        training_f1score.append(f1_score(lbls_vld, pred, average = 'weighted'))\n",
    "    \n",
    "#     print \" average training accuracy\", np.mean(training_accuracy)\n",
    "#     print \"average f1Score \", np.mean(training_f1score)\n",
    "    clf.fit(features_train,labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    \n",
    "    accuracy = accuracy_score(labels_test, pred)\n",
    "    f1_score = f1_score(labels_test, pred, average = 'weighted')\n",
    "    \n",
    "    return (accuracy, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
